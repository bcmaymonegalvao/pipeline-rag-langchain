# ğŸš€ MIGUEL - Chatbot didÃ¡tico

> âœ¨ **Pipeline didÃ¡tico de Retrieval-Augmented Generation (RAG)** construÃ­do com **LangChain** â€” focado em um pipeline *mÃ­nimo* e reproduzÃ­vel: **HuggingFace embeddings â†’ FAISS retriever â†’ LLM local (FLANâ€‘T5)**. Ideal para ensinar conceitos modernos de RAG passo a passo com **controles interativos**.

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-Core-000?style=for-the-badge&logo=langchain)](https://langchain.com)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-Transformers-FFB000?style=for-the-badge)](https://huggingface.co/transformers)
[![FAISS](https://img.shields.io/badge/Vector-FAISS-7B61FF?style=for-the-badge)](https://faiss.ai)

[ğŸ¯ Quickstart](#-quickstart) â€¢ [ğŸ›ï¸ Controles Interativos](#ï¸-controles-interativos) â€¢ [ğŸ“š Como funciona](#-como-funciona) â€¢ [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura) â€¢ [ğŸ“‹ Roadmap](#-roadmap)

</div>

---

## ğŸ“‚ Estrutura do Projeto

```
Miguel_LLM-educacional/
â”œâ”€â”€ ğŸ“ .streamlit/          # ConfiguraÃ§Ãµes do Streamlit
â”œâ”€â”€ ğŸ“ config/              # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ ğŸ“ data/                # Datasets, PDFs e corpus
â”œâ”€â”€ ğŸ“ docs/                # DocumentaÃ§Ã£o
â”œâ”€â”€ ğŸ“ models/              # Modelos treinados
â”œâ”€â”€ ğŸ“ notebooks/           # Jupyter notebooks
â”œâ”€â”€ ğŸ“ src/                 # CÃ³digo-fonte
â”‚   â”œâ”€â”€ ğŸ“ app/             # AplicaÃ§Ã£o Streamlit
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ app.py           # Interface principal
â”‚   â”‚   â””â”€â”€ ğŸ run_app.py       # Script de execuÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“ core/            # LÃ³gica RAG/LLM
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ process.py       # Pipeline de processamento
â”‚   â”‚   â”œâ”€â”€ ğŸ train_model.py   # Treinamento
â”‚   â”‚   â””â”€â”€ ğŸ utils.py         # UtilitÃ¡rios do core
â”‚   â”œâ”€â”€ ğŸ“ utils/           # UtilitÃ¡rios gerais
â”‚   â”‚   â””â”€â”€ ğŸ __init__.py
â”‚   â””â”€â”€ ğŸ __init__.py
â”œâ”€â”€ ğŸ“ tests/               # Testes unitÃ¡rios
â”œâ”€â”€ ğŸ“¦ .gitignore
â”œâ”€â”€ ğŸ“¦ .pre-commit-config.yaml
â”œâ”€â”€ ğŸ“ README.md
â”œâ”€â”€ ğŸ“¦ pyproject.toml
â”œâ”€â”€ ğŸ“¦ requirements.txt
â””â”€â”€ ğŸ“¦ runtime.txt
```

---


## ğŸ¯ Destaques

<table>
<tr>
<td>

**ğŸ“ DidÃ¡tico**
- Pipeline minimalista e bem documentado
- Exemplos prÃ¡ticos passo a passo
- **Controles interativos** para experimentar parÃ¢metros

</td>
<td>

**âš¡ Performance**
- Embeddings leves (MiniLM)
- Ãndice FAISS otimizado
- Funciona em CPU

</td>
<td>

**ğŸ”§ FlexÃ­vel**
- LLM local (FLAN-T5) por padrÃ£o
- Base de conhecimento expansÃ­vel via PDFs
- **Observabilidade didÃ¡tica** (mÃ©tricas e evidÃªncias)

</td>
</tr>
</table>

---

## ğŸ§° Stack TecnolÃ³gico

<div align="center">

| Categoria | Tecnologia | DescriÃ§Ã£o |
|-----------|------------|-----------|
| **ğŸ§  LLM** | FLAN-T5 (local) | Modelo de linguagem para geraÃ§Ã£o |
| **ğŸ” Embeddings** | HuggingFace MiniLM | Embeddings rÃ¡pidos e leves |
| **ğŸ“Š Vector Store** | FAISS | Ãndice vetorial para busca por similaridade |
| **âš™ï¸ Framework** | LangChain | OrquestraÃ§Ã£o do pipeline RAG |
| **ğŸ–¥ï¸ Interface** | Streamlit | UI interativa com controles didÃ¡ticos |
| **ğŸ Linguagem** | Python 3.10+ | Linguagem principal do projeto |

</div>

> **ğŸ’¡ Filosofia do projeto**: Orientado ao ensino, com base pequena e controlÃ¡vel, Ã­ndice FAISS simples e LLM local (FLAN-T5) para que estudantes executem tudo sem serviÃ§os externos.

---

## ğŸ›ï¸ Controles Interativos (como usar o aplicativo)

O MIGUEL foi feito para **aprender fazendo**. Na barra lateral do aplicativo (sidebar), vocÃª encontra **controles que mudam o comportamento** do RAG e do LLM.

### ğŸ§­ NavegaÃ§Ã£o do aplicativo
- **Chat**: onde vocÃª faz perguntas e vÃª **resposta + evidÃªncias** (trechos recuperados).
- **Documentos**: onde vocÃª **envia PDFs** para expandir a base de conhecimento.
- **GlossÃ¡rio & Ajuda**: explica todos os termos tÃ©cnicos do app (RAG, embeddings, FAISS, retriever etc.).

### 1) ğŸ” Top-k (k): trechos recuperados
**O que controla:** quantos trechos do FAISS o sistema recupera para â€œalimentarâ€ o LLM.

- **k menor (ex.: 1â€“2)**: respostas podem ficar **rÃ¡pidas**, mas podem faltar evidÃªncias/contexto.
- **k maior (ex.: 5â€“8)**: mais contexto, mas pode entrar **ruÃ­do** (trechos pouco relevantes).

âœ… **SugestÃ£o didÃ¡tica:** faÃ§a a mesma pergunta com k=2 e depois k=6 e compare:
- A resposta mudou?
- As evidÃªncias ficaram mais relevantes?

### 2) ğŸšï¸ Temperatura (criatividade)
**O que controla:** quanta â€œaleatoriedadeâ€ o LLM usa para gerar respostas.

- **temperatura baixa (0.0â€“0.3)**: mais **estÃ¡vel** e â€œobjetivaâ€.
- **temperatura mÃ©dia (0.4â€“0.8)**: equilÃ­brio.
- **temperatura alta (0.9â€“1.2)**: mais variaÃ§Ã£o, mas pode aumentar erros.

âœ… **SugestÃ£o didÃ¡tica:** pergunte algo conceitual (â€œo que Ã© RAG?â€) e veja se, com temperatura alta, aparecem variaÃ§Ãµes e imprecisÃµes.

### 3) ğŸ§¾ Tamanho mÃ¡ximo da resposta (tokens)
**O que controla:** o quanto o modelo pode escrever.

- **baixo (64â€“256)**: respostas curtas (bom para exercÃ­cios).
- **alto (512â€“1024)**: respostas mais longas (pode aumentar tempo de execuÃ§Ã£o).

âœ… **SugestÃ£o didÃ¡tica:** combine com Top-k:
- Se aumentar muito k e tokens, o tempo tende a aumentar.

### 4) âœ… BotÃ£o â€œAplicarâ€
Ao clicar em **Aplicar**, o pipeline Ã© **recarregado** com os novos parÃ¢metros.

> Importante: alteraÃ§Ãµes sÃ³ entram em vigor apÃ³s **Aplicar**.

### 5) â†©ï¸ BotÃ£o â€œPadrÃ£oâ€
Restaura os valores recomendados (baseline didÃ¡tico), por exemplo:
- **Top-k = 3**
- **Temperatura = 0.7**
- **Tokens = 512**

âœ… Use â€œPadrÃ£oâ€ quando quiser voltar ao comportamento â€œnormalâ€ apÃ³s experimentar.

### 6) ğŸ“ Upload de PDFs (aba Documentos)
**O que acontece ao enviar um PDF:**
1. O texto Ã© dividido em trechos (chunking)
2. Cada trecho vira embedding (vetor)
3. Tudo Ã© indexado no FAISS
4. No Chat, o retriever busca trechos similares Ã  pergunta

âœ… **ExercÃ­cio sugerido:** envie um PDF sobre um tema e pergunte algo especÃ­fico do conteÃºdo.
- Veja se o app mostra evidÃªncias (trechos) que sustentam a resposta.

### 7) ğŸ§¾ EvidÃªncias (trechos recuperados)
ApÃ³s perguntar no Chat, o app mostra:
- **Resposta gerada**
- **EvidÃªncias utilizadas** (trechos recuperados)

âœ… **Objetivo didÃ¡tico:** verificar se a resposta estÃ¡ **ancorada** em evidÃªncias, nÃ£o apenas â€œcriando textoâ€.

### 8) ğŸ“ˆ MÃ©tricas da sessÃ£o
O app exibe:
- Total de perguntas
- Tempo mÃ©dio de resposta
- Ãšltimo tempo de resposta

âœ… **Experimento:** aumente Top-k e tokens e veja o impacto no tempo.

---

## ğŸ—ï¸ Arquitetura

```mermaid
flowchart TB
    A["ğŸ“„ Documentos de exemplo / PDFs"] --> B["ğŸ§¹ Limpar e dividir em trechos (chunking)"]
    B --> C["ğŸ” RepresentaÃ§Ãµes vetoriais (MiniLM)"]
    C --> D[("ğŸ“š Ãndice FAISS")]
    D --> E{"Top-k Similaridade (k)"} 
    E --> F["ğŸ§  Cadeia de Perguntas & Respostas (QA)"]
    F --> G["ğŸ¤– LLM local (FLAN-T5)"]
    G --> H["ğŸ§¾ Resposta + EvidÃªncias"]
```

### ğŸ”§ Componentes Principais

- **ğŸ“ Corpus**: strings de exemplo + documentos enviados (PDFs)
- **ğŸ§® Embeddings**: `sentence-transformers/all-MiniLM-L6-v2`
- **ğŸ—ƒï¸ Vector Store**: FAISS
- **ğŸ” Retriever**: busca por similaridade com Top-k configurÃ¡vel
- **ğŸ¤– LLM**: FLAN-T5 local via `transformers`
- **ğŸ”— Chain**: RetrievalQA (LangChain)

---

## ğŸš€ Quickstart

### 1ï¸âƒ£ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/miguel-chatbot-didatico.git
cd miguel-chatbot-didatico

# Ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# DependÃªncias
pip install -U pip
pip install streamlit faiss-cpu sentence-transformers langchain langchain-community transformers torch pypdf
```

### 2ï¸âƒ£ ExecuÃ§Ã£o (Streamlit)

```bash
streamlit run app.py
```

Abra no navegador o endereÃ§o exibido no terminal (geralmente `http://localhost:8501`).

---

## ğŸ“š Como Funciona

### ğŸ”„ Fluxo do Pipeline

1. **ğŸ“„ Documentos**: base inicial + PDFs enviados
2. **ğŸ”¤ Embeddings**: texto â†’ vetores (MiniLM)
3. **ğŸ—„ï¸ IndexaÃ§Ã£o**: vetores â†’ Ã­ndice FAISS
4. **ğŸ” Retrieval**: retorna Top-k trechos similares
5. **ğŸ§  GeraÃ§Ã£o**: LLM gera resposta usando o contexto
6. **âœ… SaÃ­da didÃ¡tica**: resposta + evidÃªncias + mÃ©tricas

---

## ğŸ§ª AvaliaÃ§Ã£o e Testes (didÃ¡tico)

### ğŸ¯ MÃ©tricas Qualitativas
- **Groundedness**: a resposta reflete evidÃªncias?
- **RelevÃ¢ncia**: os trechos recuperados fazem sentido?
- **CoerÃªncia**: a resposta estÃ¡ clara e consistente?

### ğŸ§© Atividades sugeridas (para sala de aula)
1. Perguntar a mesma coisa variando **Top-k**
2. Comparar respostas com **temperatura baixa vs alta**
3. Enviar um PDF e testar perguntas especÃ­ficas do documento
4. Verificar se as evidÃªncias sustentam a resposta

---

## ğŸ“‹ Roadmap

### ğŸ¯ PrÃ³ximas Features
- [ ] **MMR Retriever** (diversidade de trechos)
- [ ] **PersistÃªncia do Ã­ndice FAISS** (save/load)
- [ ] **Mais loaders** (Markdown, TXT)
- [ ] **Dashboard de avaliaÃ§Ã£o** (mÃ©tricas e logs)

### ğŸ¨ Melhorias de UX
- [ ] **Logs estruturados**
- [ ] **Cache de embeddings**
- [ ] **Docker**
- [ ] **Templates didÃ¡ticos** (exercÃ­cios prontos)

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/minha-feature`)
3. Commit (`git commit -m "Minha melhoria"`)
4. Push (`git push origin feature/minha-feature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License â€” veja [LICENSE](LICENSE).

---

## ğŸ™ Agradecimentos

- **ğŸ¤— HuggingFace** pelos modelos e transformers
- **ğŸ¦œ LangChain** pelo framework RAG
- **ğŸ” FAISS** pela busca vetorial eficiente
- **ğŸ Python Community** pelas bibliotecas
